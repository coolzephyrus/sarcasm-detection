{"cells":[{"cell_type":"code","source":["pip install dgl"],"metadata":{"id":"Q0UGc8QHoY6A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"id":"jIZ43sRjqeWZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"Mhh6BsAIqyVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XW2yNJ283p8W"},"outputs":[],"source":["import os\n","import sys\n","import json\n","import random\n","import time\n","import re\n","import datetime\n","import pickle\n","\n","from tqdm import tqdm\n","\n","import numpy as np\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","from keras.preprocessing.sequence import pad_sequences\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n","\n","from transformers import BertForSequenceClassification,  DistilBertForSequenceClassification, RobertaForSequenceClassification\n","from transformers import BertForMaskedLM, DistilBertForMaskedLM, RobertaForMaskedLM\n","from transformers import BertTokenizer, DistilBertTokenizer, RobertaTokenizer\n","\n","from transformers import BertConfig, DistilBertConfig, RobertaConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup \n","\n","from transformers import logging\n","logging.set_verbosity_error()\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwaYWaFt3p8X"},"outputs":[],"source":["import dgl\n","from dgl import DGLGraph\n","from dgl.data import MiniGCDataset\n","\n","from dgl.nn.pytorch import conv as dgl_conv\n","from dgl.data import citegrh\n","\n","# Load Pytorch as backend\n","dgl.load_backend('pytorch')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ypyq6efJ3p8Y"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"9WGtz-Mw3p8Y"},"source":["### Dataset Configs"]},{"cell_type":"code","source":["# set path variables\n","basepath = '/content/gdrive/MyDrive/ljmu-ms-thesis/'\n","datapath = '/content/gdrive/MyDrive/ljmu-ms-thesis/data/'\n","modelpath =  '/content/gdrive/MyDrive/ljmu-ms-thesis/model/'"],"metadata":{"id":"H8OAiZoxB5NP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VgGaOi73p8Z"},"outputs":[],"source":["EDGE_TYPE = {\n","    'bidirectional': 1,\n","    'input2COMET': 2,\n","    'COMET2input': 3\n","}"]},{"cell_type":"code","source":["# common config settings\n","EPOCHS = 10\n","TOTAL_ITERATIONS = 3\n","TEST_SIZE = 0.2\n","MAX_LEN = 32\n","BATCH_SIZE = 16\n","RANDOM_STATE = 2022\n","LEARNING_RATE = 2e-5\n","EPS = 1e-8\n","SEED_VAL = 42"],"metadata":{"id":"ZPuVpVU_B8mO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# choose one model at a time\n","#model_name = 'bert'\n","model_name = 'roberta'\n","#model_name = 'distilbert'"],"metadata":{"id":"__mG5ATjCI4d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MeZMSQPY3p8Z"},"source":["### Dataset Load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g16PWKy93p8a"},"outputs":[],"source":["def load_dataset(filename):\n","    data = []\n","    with open(filename) as f:\n","        for line in f:\n","            entry = {}\n","            entry['sentences'] = []\n","            \n","            line = line.strip()\n","            d = json.loads(line)\n","            \n","            entry['sentences'].append(d['sentence'])\n","            entry['label'] = int(d['label'])\n","            \n","            for k in d['common_sense'].keys():\n","                if k == 'xWant' or k == 'xEffect':\n","                    entry['sentences'].append(d['common_sense'][k])\n","            data.append(entry)\n","                \n","    return data    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xei_52WX3p8a"},"outputs":[],"source":["read_filename = 'amazon_'+ model_name +'_comet.json'\n","dataset = load_dataset(datapath + read_filename)"]},{"cell_type":"markdown","metadata":{"id":"zIE4jlUV3p8a"},"source":["### Pre-trained BERT model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"07q5Tywt3p8a"},"outputs":[],"source":["def get_attn(input_ids):\n","    attention_masks = []\n","\n","    for sent in input_ids:\n","        att_mask = [int(token_id > 0) for token_id in sent]\n","        attention_masks.append(att_mask)\n","    return attention_masks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6Pcjxqe3p8b"},"outputs":[],"source":["# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n","def get_tokenizer(model_name):\n","    if model_name == 'distilbert':\n","        tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n","    elif model_name == 'bert':\n","        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","    elif model_name == 'roberta':\n","        tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n","    return tokenizer\n","\n","tokenizer = get_tokenizer(model_name)     "]},{"cell_type":"code","source":["# load the previously trained comet model\n","load_model = model_name +'_comet.pb'\n","model = torch.load(modelpath + load_model, map_location=torch.device(device) )\n","model.to(device)"],"metadata":{"id":"G9IIgx8llrN1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AlajACNN3p8b"},"source":["## Load dataset from pickle dump"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xolheKJw3p8b"},"outputs":[],"source":["def get_pickle_file(filename):\n","    with open(filename, 'rb') as f:\n","        return pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W5laTqhx3p8b"},"outputs":[],"source":["MAX_LEN = 128\n","\n","def create_dataset_cached(dataset):\n","    all_data = []\n","    \n","    for data, label in tqdm(dataset):\n","        input_ids = []\n","        \n","        input_ids.append(data['sentence'])\n","        \n","        for s in data['support']:\n","            input_ids.append(s)\n","            \n","        input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n","        att_mask = torch.tensor(get_attn(input_ids))\n","        input_ids = torch.tensor(input_ids)\n","        \n","\n","        loss, hidden_state = model(input_ids.to(device), attention_mask=att_mask.to(device), return_dict=False, output_hidden_states=False)\n","        \n","        output = hidden_state[-1][:, 0, :].detach().to('cpu')\n","        \n","        torch.cuda.empty_cache()\n","\n","        graph = dgl.graph((torch.tensor([0, 0]), \n","                               torch.tensor([1, 2]))) # Edge type is by default chosen as input to comet\n","            \n","        graph.ndata['x'] = torch.tensor(output)\n","        all_data.append((graph, label, data['raw_sentence']))\n","    return all_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y-AUeHpN3p8c"},"outputs":[],"source":["trainset_, validationset_ = get_pickle_file(modelpath + 'trainset-comet-' + model_name +'.data'), get_pickle_file(modelpath + 'validationset-comet-' + model_name + '.data')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGOG8fDL3p8c"},"outputs":[],"source":["trainset, validationset = create_dataset_cached(trainset_), create_dataset_cached(validationset_)"]},{"cell_type":"markdown","metadata":{"id":"cy_jF-F_3p8c"},"source":["### Training Data generation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3UXu2DL3p8c"},"outputs":[],"source":["def collate(samples):\n","    # The input `samples` is a list of pairs\n","    #  (graph, label).\n","    graphs, labels, raw_sentence = map(list, zip(*samples))\n","    batched_graph = dgl.batch(graphs)\n","    return batched_graph, torch.tensor([labels]), raw_sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXc2OfJv3p8c"},"outputs":[],"source":["BATCH_SIZE = 16"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1XbMPK43p8c"},"outputs":[],"source":["train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate)\n","test_loader = DataLoader(validationset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate)"]},{"cell_type":"markdown","metadata":{"id":"OwLCxfZu3p8e"},"source":["## Basic SAGE Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QCvIv3ct3p8e"},"outputs":[],"source":["class GraphSAGEModel(nn.Module):\n","    def __init__(self,\n","                 in_feats,\n","                 n_hidden,\n","                 out_dim,\n","                 n_layers,\n","                 activation,\n","                 dropout,\n","                 aggregator_type):\n","        super(GraphSAGEModel, self).__init__()\n","        self.node_count = 3\n","        self.layers = nn.ModuleList()\n","        self.index = torch.tensor([1, 2]).to(device)\n","\n","        # input layer\n","        self.layers.append(dgl_conv.SAGEConv(768, n_hidden, aggregator_type,\n","                                         feat_drop=dropout, activation=None))\n","        self.lin1 = nn.Linear(64, 5)\n","        self.lin2 = nn.Linear(5 * self.node_count, 2)\n","\n","    def forward(self, g, features):\n","        h = features\n","        for layer in self.layers:\n","            h = layer(g, h)  \n","            \n","        x = self.lin1(h.view(-1, self.node_count, 64))\n","        x = self.lin2(x.view(-1, 5 * self.node_count))\n","        \n","        return F.log_softmax(x.view(-1, 2), dim=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ilgDwieF3p8e"},"outputs":[],"source":["# using default Hyperparameters\n","n_hidden = 64\n","n_layers = 2\n","dropout = 0.5\n","aggregator_type = 'gcn'\n","n_classes = 2\n","in_feats = trainset[0][0].ndata['x'].shape[1]\n","\n","def reset_model():\n","    weight_decay = 5e-4\n","    lr = 2e-3\n","    neg_sample_size = 100\n","\n","    model = GraphSAGEModel(in_feats,\n","                             n_hidden,\n","                             n_classes,\n","                             n_layers,\n","                             F.relu,\n","                             dropout,\n","                             aggregator_type)\n","\n","    model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    return model, optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51ZAWRDh3p8e"},"outputs":[],"source":["# use optimizer\n","criteria = nn.NLLLoss()"]},{"cell_type":"markdown","metadata":{"id":"EcZ9Tcm53p8e"},"source":["### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYtNnQPw3p8e"},"outputs":[],"source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S6wLXT2P3p8f"},"outputs":[],"source":["def train(model, optimizer, epoch):\n","    model.train()\n","    \n","    eval_accuracy = 0\n","    nb_eval_steps = 0\n","    \n","    for batch, (g, label, _) in enumerate(train_loader):\n","        g = g.to(device)\n","        output = model(g, g.ndata['x'])\n","        loss = criteria(output, label.view(-1).to(device))\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        eval_accuracy += loss.item()\n","        nb_eval_steps += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4g_vY9H3p8f"},"outputs":[],"source":["def test(model, test_loader):   \n","    eval_accuracy = 0\n","    nb_eval_steps = 0\n","    \n","    model.eval()\n","    \n","    all_predictions = []\n","    all_labels = []\n","    \n","    for batch, (g, label, _) in enumerate(test_loader):\n","        g = g.to(device)\n","        \n","        with torch.no_grad():\n","            output = model(g, g.ndata['x']) \n","        \n","\n","        logits = output.detach().cpu().numpy()\n","        label_ids = label.to('cpu').numpy()\n","        \n","        prediction = list(np.argmax(logits, axis=1).flatten())\n","        all_predictions.extend(prediction)\n","        all_labels.extend(label_ids.flatten())\n","        \n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","        \n","    \n","    accuracy = eval_accuracy/nb_eval_steps\n","    f1 = f1_score(all_predictions, all_labels, average = 'macro')\n","    precision = precision_score(all_predictions, all_labels, average = 'macro')\n","    recall = recall_score(all_predictions, all_labels, average = 'macro')\n","        \n","    matrix = confusion_matrix(all_predictions, all_labels)\n","\n","    tp = matrix[0][0]\n","    fp = matrix[0][1]\n","    fn = matrix[1][0]\n","    tn = matrix[1][1]\n","\n","    return [f1, precision, recall, accuracy]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RF0UQLH03p8f"},"outputs":[],"source":["def save_model(filename = modelpath + model_name +'_gcn_comet.pb'):\n","    torch.save(model, filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDpw7oeh3p8f"},"outputs":[],"source":["def run(model, optimizer):\n","    best_results = [0, 0, 0, 0]\n","    t0 = time.time()\n","    for epoch in range(EPOCHS):\n","        train(model, optimizer, epoch)\n","        elapsed = format_time(time.time() - t0)\n","        print('Epoch {:} / {:}    Elapsed: {:}.'.format(epoch_i + 1, EPOCHS, elapsed))  \n","        results = test(model, test_loader)      \n","        if results[0] > best_results[0]:\n","            best_results = results\n","            save_model()\n","    return best_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4t2WSvrh3p8g"},"outputs":[],"source":["all_results = []\n","t0 = time.time()\n","\n","for iteration in range(TOTAL_ITERATIONS):\n","    it0 = time.time()\n","    print('-'*50)\n","    print('Iteration {:2d}'.format(iteration+1))\n","    print('-'*50)\n","    model, optimizer = reset_model()\n","    result = run(model, optimizer)\n","    all_results.append(result)\n","    print('-'*50)\n","    print('Result for this iteration: ', result)\n","    print('Time taken for this iteration: {:}'.format(format_time(time.time() - it0)))\n","\n","# Final results is the average of all the iterations\n","final_results = [sum(value)/len(value) for value in zip(*all_results)]\n","\n","print('-'*50)\n","print('Final Results for the baseline model: ' + model_name)\n","print('-'*50)\n","print('F1-score: {0:.4f}'.format(final_results[0]))\n","print('Precision: {0:.4f}'.format(final_results[1]))\n","print('Recall: {0:.4f}'.format(final_results[2]))\n","print('Accuracy: {0:.4f}'.format(final_results[3]))\n","print('Time Taken: {:}'.format(format_time(time.time() - t0)))\n","print('-'*50)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"name":"gcn-comet-plm.ipynb","provenance":[{"file_id":"1PmJH1DXF28uQyy3PCajjSYfCnhPuzW0w","timestamp":1654252637251},{"file_id":"1uWmHCxoflZVEminogHYZ2G3F_JckZpay","timestamp":1653731754623}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}